---
title: "Computer Intensive Methods for Bioinformatics - Homework 1"
author: "Pieter Moris"
date: "17 november 2015"
output: html_document
---

#Question 1: Permutations P-value

We will investigate the influence of the number of permutations on tests of inference. We will use the golub dataset as an example. This dataset consists of the gene expression levels for **3051 genes** from a leukemia microarray study. There are **two tumor classes** in the samples: 27 originate from acute lymphoblastic leukemia (ALL), whereas the remaining 11 samples came from acute myeloid leukemia (AML) tumors. The question of interest is which of these 3051 genes are **differentially expressed** across the two conditions, i.e. $H_0: \mu_{healthy} = \mu_{diseased} \text{ vs } H_a: \mu_{healthy} \ne \mu_{diseased}$. We will use a significance level $\alpha = 0.1$ for all the following tests.


```{r, warning=FALSE,message=FALSE}
library(Biobase)
library("multtest")
```
```{r}
data(golub)
head(golub)
golub.cl # 0 ALL vs 1 AML
```

We could perform a simple t-test for each gene (or hypothesis) separetely:

```{r}
library(ggplot2)
tstatistics <- mt.teststat(X=golub,classlabel = golub.cl,test="t.equalvar")
pvalues<- 1 - pt(abs(tstatistics),df=dim(golub)[2]-2)
ggplot() + geom_point(aes(x=seq_along(tstatistics),y=tstatistics,colour=pvalues>0.1))
ggplot() + geom_histogram(aes(x=pvalues,y=..density..),binwidth=0.1,alpha=0.8,colour='darkgreen',fill='white')
```

However, because we are conducting a large amount of tests we are **inflating the type 1 error**: the chance of finding at least one false positive quickly approaches 1 as the number of tests increases $1-(1-\alpha)^m$, where $m$ is the number of tests and $1-\alpha$ is the confidence level for 1 test, i.e. the probability of not making any type one errors.

To remedy this we will **adjust for multiplicity** by adjusting either the **family wise error rate**, which controls the probability of making at least 1 type one error, or the **false discovery rate**, which controls the proportion of false positives amongst all rejected hypotheses.

```{r}
adjusted = mt.rawp2adjp(pvalues, proc=c("Bonferroni", "Holm", "BH"),alpha=0.1)
adjusted$adjp[1:10, ] # ordered from low to high!
mt.plot(adjusted$adjp,tstatistics,plottype="pvsr",proc=dimnames(adjusted$adjp)[[2]],leg=c(1700,0.95),lty=1,col=1:4,lwd=2)
treject <- sum(adjusted$adjp[,4]< 0.1)
```

The above tests rely on distributional assumptions of the t-statistic. We can avoid this by utilising **resampling** methods. In the following we will use a permutation strategy to approximate the sampling distribution of the t-statistic **under the null hypothesis** of no differential expression, i.e. each sample could belong to either the ALL or AML group.

```{r}
permutationPvalues <- function(x,B,grouping) {
  genes <- dim(x)[1]
  nsamples <- ncol(x)
  t.perm <- matrix(nrow=genes,ncol=B)
  
  for(b in 1:B) {
    permutedColumns <- sample(nsamples,replace=FALSE) # permutation of 1:n by which we will select matrix columns
    group1.col.perm <- permutedColumns[grouping == 0] # assign first n1 samples to group 1
    group1.perm <- x[,group1.col.perm]
    group2.col.perm <- permutedColumns[grouping == 1] # assign remaining n2 samples to group 2
    group2.perm <- x[,group2.col.perm]
    x.perm <- cbind(group1.perm,group2.perm) # new matrix with permutated columns
    t.perm[,b] <- mt.teststat(X=x.perm,classlabel = grouping,test="t.equalvar") # perform t-test for each row
    # each row of this matrix contains a row of B t statistics, one row per gene, 
    # based on samples that were permuted across conditions.
  }
  # calculate the observed test statistic per gene/row
  t.obs <-mt.teststat(X=x,classlabel = grouping,test="t.equalvar")
  
  # calculate the number of test statistics that are larger
  # in absolute value than the observed test statistic of each gene,
  # this gives us the p-values (using the joint distribution)
  p.perm <- c(1:genes) # vector containing a p-value for each gene
  p.perm <- sapply(t.obs, function(x) sum( abs(t.perm) > abs(x) ) / (B * genes) )
#   for (gene in 1:genes) {
#     p.perm[gene] <- sum(abs(t.perm) > abs(t.obs[gene])) / (B * genes)
#     }
  return(p.perm)
} 

golub.perm <- permutationPvalues(golub,50,golub.cl)
ggplot() + geom_histogram(aes(x=golub.perm,y=..density..),binwidth=0.1,alpha=0.8,colour='darkgreen',fill='white')
```

Just as before, we should apply a **multiplicity** correction:


```{r}
adjusted.perm = mt.rawp2adjp(golub.perm, proc=c("Bonferroni", "Holm", "BH"),alpha=0.1)
adjusted.perm$adjp[1:10, ] # ordered from low to high!
mt.plot(adjusted.perm$adjp,tstatistics,plottype="pvsr",proc=dimnames(adjusted$adjp)[[2]],leg=c(1700,0.95),lty=1,col=1:4,lwd=2)
```

Where are these zeros coming from? Well, we only used 50 permutations, so there are a number of genes for which none of the permuted test statistics are more extreme than the observed one, resulting in a p-value of zero. Let's see if we can improve our result by increasing the number of permutations.

```{r}
Sys.time()->start;
i = 1
golub.perm = list()
adjusted.perm = list()
rejected <- c()
for(B in c(50,75,100,500,1000)){
  golub.perm[[i]] <- permutationPvalues(golub,B,golub.cl)
  print(ggplot() + geom_histogram(aes(x=golub.perm[[i]],y=..density..),binwidth=0.1,alpha=0.8,colour='darkgreen',fill='white'))
  adjusted.perm[[i]] = mt.rawp2adjp(golub.perm[[i]], proc=c("BH"),alpha=0.1)
  print(adjusted.perm[[i]]$adjp[1:10, ]) # ordered from low to high!
  mt.plot(adjusted.perm[[1]]$adjp,tstatistics,plottype="pvsr",proc=dimnames(adjusted.perm[[i]]$adjp)[[2]],leg=c(1700,0.95),lty=1,col=1:4,lwd=2)
  rejected[i] <- sum(golub.perm[[i]] < 0.1)
  i = i+1
}

ggplot() + geom_line(aes(y=rejected,x=c(50,75,100,500,1000)),alpha=0.8,colour='darkgreen') + ylab("Number of rejected hypotheses") + xlab('Number of permutations')
print(Sys.time()-start);

treject # rejected hypotheses by t-test
```